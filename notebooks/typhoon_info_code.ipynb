{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22793615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Notebook cleans the data of the compiled typhoon info dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f665f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33388e60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Disclaimer: Generative AI was used to convert typhoon report screenshots (Source: PAGASA) into CSV format\n",
    "\n",
    "# A threshold of 150mm in a 24-hour period was utilized to identify High-Intensity Rainfall events. This corresponds to the PAGASA Red Rainfall Warning level, which indicates a high potential for severe flooding and necessitates immediate action. By isolating typhoons that triggered this threshold at at least one station, the study focuses on events where infrastructure resilience was most critical.\n",
    "\n",
    "# 1. Grab the paths of all CSV files in your folder\n",
    "filename = './data/typhoon-info/compiled_2019-2025.csv' \n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Clean it up before the merge\n",
    "mapping_df = pd.read_csv('data/geospatial-data/station_location_mapping.csv')\n",
    "\n",
    "# Remove geo columns from raw data if they exist to avoid the \"x/y\" issue\n",
    "df = df.drop(columns=['Province', 'Region'], errors='ignore')\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(df, mapping_df, on='Location', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We impute the empty cells based on the locality\n",
    "\n",
    "rain_col = \"Max 24-hour Rainfall (mm)\"\n",
    "gust_col = \"Peak Gust (10 mins sustained) (m/s)\"\n",
    "\n",
    "df[rain_col] = df[rain_col].replace(0, np.nan)\n",
    "df[gust_col] = df[gust_col].replace(0, np.nan)\n",
    "\n",
    "# 1. RAINFALL: Tiered Local Median (Province -> Region)\n",
    "# This maintains the integrity of rainfall which will be used as a main metric, while imputing for any missing data\n",
    "df[rain_col] = df.groupby(['Typhoon', 'Year', 'Province'])[rain_col].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "df[rain_col] = df.groupby(['Typhoon', 'Year', 'Region'])[rain_col].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "\n",
    "# 2. GUST: Tiered Local Mean (Province -> Region -> National)\n",
    "# Mean and National locality is both used because Peak Gust is a lot more consistent\n",
    "\n",
    "df[gust_col] = df.groupby(['Typhoon', 'Year', 'Province'])[gust_col].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "df[gust_col] = df.groupby(['Typhoon', 'Year', 'Region'])[gust_col].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "df[gust_col] = df.groupby(['Typhoon', 'Year'])[gust_col].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# 3. Drop rows with no Rainfall\n",
    "df = df.dropna(subset=[rain_col])\n",
    "\n",
    "# 4. Fill remaining Gust NaNs with 0 (These are Rain-Heavy storms)\n",
    "df[gust_col] = df[gust_col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbeef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your cleaned dataframe to a specific folder\n",
    "# 'index=False' prevents pandas from adding an extra column of numbers at the start\n",
    "df.to_csv('data/typhoon-info/cleaned_2019-2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
